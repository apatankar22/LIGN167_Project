# -*- coding: utf-8 -*-
"""LIGN 167 Project Behavorial Q. Chatbox IP.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1k9THQgxMpXZpoaKftxkfLnrIvf6cEf-9
"""

pip install --upgrade openai

import os
import openai

openai.api_key = "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"

input_prompts = "The following is a conversation with an AI assistant. The assistant is helpful, creative, clever, and very friendly.\n\nHuman: Hello, who are you? \nAI: I am an AI created by OpenAI. How can I help you today?\nHuman: Hello, I am a data science student looking for a internship. Do a mock interview by asking me about my education and experiences. \nAI:"
response = openai.Completion.create(
  model="text-davinci-002",
  prompt=input_prompts,
  temperature=0.9,
  max_tokens=150,
  top_p=1,
  frequency_penalty=0.0,
  presence_penalty=0.6,
  stop=[" Human:", " AI:"]
)

ai_response = dict(response.get("choices")[0])["text"].strip()
ai_response

user_response = "I'm a third year computer science student at UC San Diego"

input_prompts += ai_response + "\nHuman: " + user_response
input_prompts

response = openai.Completion.create(
  model="text-davinci-002",
  prompt=input_prompts,
  temperature=0.9,
  max_tokens=150,
  top_p=1,
  frequency_penalty=0.0,
  presence_penalty=0.6,
  stop=[" AI:"]
)

ai_response = dict(response.get("choices")[0])["text"].strip()
ai_response

#this complete chunk of code should have the model ask 5 questions 
input_prompts = "The following is a conversation with an AI assistant. The assistant is helpful, creative, clever, and very friendly.\n\nHuman: Hello, who are you? \nAI: I am an AI created by OpenAI. How can I help you today?\nHuman: Hello, I am a data science student looking for a internship. Do a mock interview by asking me about my education and experiences. \nAI:"
response = openai.Completion.create(
  model="text-davinci-002",
  prompt=input_prompts,
  temperature=0.9,
  max_tokens=150,
  top_p=1,
  frequency_penalty=0.0,
  presence_penalty=0.6,
  stop=[" Human:", " AI:"]
)

ai_response = dict(response.get("choices")[0])["text"].strip()
print(ai_response)
#TO DO: prompt user to answer here 
user_response = "this is my answer"


for i in range(5): 
  input_prompts += ai_response + "\nHuman: " + user_response
  input_prompts
  #there is another response template for other questions because the stop arg needed to be changed to prevent model from answering its own questions 
  response = openai.Completion.create(
    model="text-davinci-002",
    prompt=input_prompts,
    temperature=0.9,
    max_tokens=150,
    top_p=1,
    frequency_penalty=0.0,
    presence_penalty=0.6,
    stop=[" Human:", " AI:"]
  )

  ai_response = dict(response.get("choices")[0])["text"].strip()
  print(ai_response)
  #TO DO: prompt user to answer here 
  user_response = "this is my answer"